# -*- coding: utf-8 -*-
"""Assignment2_SijjilShabbir_452131_GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YCyPRYr4VDss6FU2RVeTbVhKb1AXjhQQ

##Assignment 2: Gen AI and it's Applications

#Name: Sijjil Shabbir
#CMS ID: 452131

Installing Required Libraries
"""

# Install dependencies
!pip install torch torchvision numpy matplotlib kaggle

"""Binding Google Drive and Uploading kaggle api"""

# Authenticate Kaggle API (upload your Kaggle API JSON key)
from google.colab import files
files.upload()  # Upload kaggle.json file

# Move kaggle.json to the correct folder and set permissions
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

from google.colab import drive
drive.mount('/content/drive')

"""Downloading the Pokemon Dataset from Kaggle (This dataset contains 7000 pokemon Images)"""

!kaggle datasets download -d lantian773030/pokemonclassification -p "/content/drive/MyDrive/PokemonDataset"

# Unzip inside Google Drive
!unzip "/content/drive/MyDrive/PokemonDataset/pokemonclassification.zip" -d "/content/drive/MyDrive/PokemonDataset"

"""Creating DataLoader and Visualizing the Data"""

import os
import torch
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from PIL import Image

# Define dataset path (modify if needed)
dataset_path = "/content/drive/MyDrive/PokemonDataset"

# Define image transformations
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize to 64x64
    transforms.ToTensor(),         # Convert to Tensor
    transforms.Normalize([0.5], [0.5])  # Normalize to range [-1, 1]
])

# Load dataset
dataset = ImageFolder(root=dataset_path, transform=transform)

# Create DataLoader
batch_size = 64
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Function to visualize a few images
def show_images(dataloader, num_images=16):
    data_iter = iter(dataloader)
    images, _ = next(data_iter)
    images = images[:num_images]

    fig, axes = plt.subplots(4, 4, figsize=(6, 6))
    for i, ax in enumerate(axes.flatten()):
        img = images[i].permute(1, 2, 0) * 0.5 + 0.5  # Denormalize
        ax.imshow(img)
        ax.axis("off")
    plt.show()

# Show sample images
show_images(dataloader)

"""##Generator Model"""

import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, z):
        return self.model(z)

# Define latent space size
latent_dim = 100
generator = Generator(latent_dim)
print(generator)

"""##Discriminator Model"""

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, img):
        return self.model(img)

discriminator = Discriminator()
print(discriminator)

"""##Model Training"""

import torch.optim as optim

# Set device (GPU if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Move models to device
generator.to(device)
discriminator.to(device)

# Loss function
criterion = nn.BCELoss()

# Optimizers
lr = 0.0002  # Learning rate
beta1 = 0.5  # Momentum term
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))

import time

# Hyperparameters
num_epochs = 100
latent_dim = 100

# Fixed noise for visualization
fixed_noise = torch.randn(16, latent_dim, 1, 1, device=device)

# Training loop
for epoch in range(num_epochs):
    start_time = time.time()

    for i, (real_images, _) in enumerate(dataloader):
        real_images = real_images.to(device)

        # Labels for real and fake images
        real_labels = torch.ones(real_images.size(0), 1, device=device)
        fake_labels = torch.zeros(real_images.size(0), 1, device=device)

        # ---- Train Discriminator ----
        optimizer_D.zero_grad()

        # Real images loss
        real_outputs = discriminator(real_images).view(-1, 1)
        real_loss = criterion(real_outputs, real_labels)

        # Generate fake images
        z = torch.randn(real_images.size(0), latent_dim, 1, 1, device=device)
        fake_images = generator(z)

        # Fake images loss
        fake_outputs = discriminator(fake_images.detach()).view(-1, 1)
        fake_loss = criterion(fake_outputs, fake_labels)

        # Total loss for Discriminator
        d_loss = real_loss + fake_loss
        d_loss.backward()
        optimizer_D.step()

        # ---- Train Generator ----
        optimizer_G.zero_grad()

        # Generate new fake images
        fake_outputs = discriminator(fake_images).view(-1, 1)
        g_loss = criterion(fake_outputs, real_labels)  # Fool the discriminator

        g_loss.backward()
        optimizer_G.step()

    # Print progress
    elapsed_time = time.time() - start_time
    print(f"Epoch [{epoch+1}/{num_epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f} | Time: {elapsed_time:.2f}s")

    # Save sample generated images every 10 epochs
    if (epoch + 1) % 10 == 0:
        with torch.no_grad():
            sample_images = generator(fixed_noise).detach().cpu()

        fig, axes = plt.subplots(4, 4, figsize=(6, 6))
        for i, ax in enumerate(axes.flatten()):
            img = sample_images[i].permute(1, 2, 0) * 0.5 + 0.5  # Denormalize
            ax.imshow(img)
            ax.axis("off")
        plt.show()

print("Training complete!")

"""Saving the Model"""

# Define save paths
generator_path = "/content/drive/MyDrive/dcgan_generator.pth"
discriminator_path = "/content/drive/MyDrive/dcgan_discriminator.pth"

# Save models
torch.save(generator.state_dict(), generator_path)
torch.save(discriminator.state_dict(), discriminator_path)

print("Models saved successfully!")

"""##Falsk App to use the Model"""

!pip install flask flask-ngrok torch torchvision

import torch
import torch.nn as nn
import numpy as np
from flask import Flask, render_template, send_file
import io
import torchvision.utils as vutils
from PIL import Image
from flask_ngrok import run_with_ngrok  # Import ngrok for Colab

# Define Generator
class Generator(nn.Module):
    def __init__(self, latent_dim=100):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, z):
        return self.model(z)

# Load trained model
device = torch.device("cpu")
latent_dim = 100
generator = Generator(latent_dim).to(device)

try:
    generator.load_state_dict(torch.load("/content/drive/MyDrive/dcgan_generator.pth", map_location=device))
    generator.eval()
    print("✅ Model loaded successfully!")
except Exception as e:
    print(f"❌ Error loading model: {e}")

# Initialize Flask app
app = Flask(__name__)
run_with_ngrok(app)  # Enable ngrok for Colab

@app.route("/generate")
def generate_image():
    noise = torch.randn(1, latent_dim, 1, 1, device=device)

    with torch.no_grad():
        fake_image = generator(noise).cpu()

    fake_image = (fake_image + 1) / 2  # Normalize to [0,1]
    img_pil = vutils.make_grid(fake_image, normalize=True).permute(1, 2, 0).numpy()
    img_pil = Image.fromarray((img_pil * 255).astype(np.uint8))

    img_io = io.BytesIO()
    img_pil.save(img_io, 'PNG')
    img_io.seek(0)

    return send_file(img_io, mimetype='image/png')

@app.route("/")
def home():
    return """<h1>Pokémon Generator</h1>
              <p>Click the button below to generate a Pokémon:</p>
              <a href='/generate'><button>Generate Pokémon</button></a>"""

if __name__ == "__main__":
    app.run()